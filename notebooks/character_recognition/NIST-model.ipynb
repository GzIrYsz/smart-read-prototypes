{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du modèle de reconnaissance de caractère basé sur le dataset MIST\n",
    "\n",
    "Dans ce notebook sera présenté la création du modèle qui permettra de **classifier** les lettres de l'alphabet de a-z et A-Z.\n",
    "\n",
    "Pour ce faire nous allons utiliser le dataset d'images prétraités créés par le notebook [NIST-preprocessing](/notebooks/notebooks/character_recognition/NIST-preprocessing.ipynb)\n",
    "\n",
    "Pour exécuter ce notebook, veillez à ce que le jeu de données soit bien sous la forme suivante.\n",
    "- data\n",
    "    - processed\n",
    "         - NIST-dataset\n",
    "            - train\n",
    "                - a000001.png\n",
    "                - a000002.png\n",
    "                ...\n",
    "                ...\n",
    "                - a00000n.png\n",
    "            - test_set\n",
    "                - a000001.png\n",
    "                - a000002.png\n",
    "                ...\n",
    "                ...\n",
    "                - a00000n.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from string import ascii_lowercase, ascii_uppercase\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Num of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation de tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des paramètres du notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIST_PROCESSED_PATH = \"../../data/processed/NIST-dataset\"\n",
    "TRAIN_SET_PATH = os.path.join(NIST_PROCESSED_PATH, \"train\", \"nist_processed_train.csv\")\n",
    "TEST_SET_PATH = os.path.join(NIST_PROCESSED_PATH, \"test\", \"nist_processed_test.csv\")\n",
    "IMG_SIZE = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation du dataset\n",
    "\n",
    "Dans cette section, nous allons charger le dataset afin d'obtenir un train_data_set, train_label_set, ainsi qu'un test_data_set et un test_label_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du dataset depuis le disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_frame = pd.read_csv(TRAIN_SET_PATH)\n",
    "test_set_frame = pd.read_csv(TEST_SET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_original_shape(y_raw_set):\n",
    "    x  = y_raw_set.shape\n",
    "    return y_raw_set.reshape(x[0], 1)\n",
    "\n",
    "def get_x_original_shape(x_raw_set):\n",
    "    x, y = x_raw_set.shape\n",
    "    return x_raw_set.reshape(x, IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_and_x_set_from_dataframe(dataframe):\n",
    "    y_raw_set = dataframe[\"label\"].to_numpy(dtype=str)\n",
    "    x_raw_set = test_set_frame.iloc[:, 2:].to_numpy(dtype=np.uint8)\n",
    "\n",
    "    y_set = get_y_original_shape(y_raw_set)\n",
    "    x_set = get_x_original_shape(x_raw_set)\n",
    "\n",
    "    return y_set, x_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, x_train = get_y_and_x_set_from_dataframe(train_set_frame)\n",
    "y_test, x_test = get_y_and_x_set_from_dataframe(test_set_frame)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère tous les labels possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [char for char in ascii_lowercase + ascii_uppercase]\n",
    "print(label_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit l'encoder à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On encode nos données au format OneShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded_train = encoder.transform(y_train)\n",
    "y_encoded_test = encoder.transform(y_test)\n",
    "y_encoded_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(41,41)),\n",
    "    layers.Flatten(input_shape=(41, 41)),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(52, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"acc\", \"categorical_crossentropy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de tensorboard si installé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_encoded_train, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du modèle sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_encoded_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
