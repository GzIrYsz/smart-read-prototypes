{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du modèle de reconnaissance de caractère basé sur le dataset MIST\n",
    "\n",
    "Dans ce notebook sera présenté la création du modèle qui permettra de **classifier** les lettres de l'alphabet de a-z et A-Z.\n",
    "\n",
    "Pour ce faire nous allons utiliser le dataset d'images prétraités créés par le notebook [NIST-preprocessing](/notebooks/notebooks/character_recognition/NIST-preprocessing.ipynb)\n",
    "\n",
    "Pour exécuter ce notebook, veillez à ce que le jeu de données soit bien sous la forme suivante.\n",
    "- data\n",
    "    - processed\n",
    "         - NIST-dataset\n",
    "            - train\n",
    "                - a000001.png\n",
    "                - a000002.png\n",
    "                ...\n",
    "                ...\n",
    "                - a00000n.png\n",
    "            - test_set\n",
    "                - a000001.png\n",
    "                - a000002.png\n",
    "                ...\n",
    "                ...\n",
    "                - a00000n.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 02:04:37.776240: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 02:04:38.120861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexandre/Programmes/Python-3.6.4/\n",
      "2023-04-21 02:04:38.120896: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-21 02:04:39.525329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexandre/Programmes/Python-3.6.4/\n",
      "2023-04-21 02:04:39.525706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexandre/Programmes/Python-3.6.4/\n",
      "2023-04-21 02:04:39.525714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from string import ascii_lowercase, ascii_uppercase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 02:04:40.721471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alexandre/Programmes/Python-3.6.4/\n",
      "2023-04-21 02:04:40.721722: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-21 02:04:40.721741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alexandre-HP-Pavilion-Laptop-14-ec0xxx): /proc/driver/nvidia/version does not exist\n",
      "2023-04-21 02:04:40.723083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 17300069916710730510\n xla_global_id: -1]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Num of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_44134/810913319.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation de tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des paramètres du notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIST_PROCESSED_PATH = \"../../data/processed/NIST-dataset\"\n",
    "TRAIN_SET_PATH = os.path.join(NIST_PROCESSED_PATH, \"train\", \"nist_processed_train.csv\")\n",
    "TEST_SET_PATH = os.path.join(NIST_PROCESSED_PATH, \"test\", \"nist_processed_test.csv\")\n",
    "IMG_SIZE = 41\n",
    "CHUNK_SIZE = 25000\n",
    "PANDA_CSV_ENGINE = \"c\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation du dataset\n",
    "\n",
    "Dans cette section, nous allons charger le dataset afin d'obtenir un train_data_set, train_label_set, ainsi qu'un test_data_set et un test_label_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du dataset depuis le disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_original_shape(y_raw_set):\n",
    "    x  = y_raw_set.shape\n",
    "    return y_raw_set.reshape(x[0], 1)\n",
    "\n",
    "def get_x_original_shape(x_raw_set):\n",
    "    x, y = x_raw_set.shape\n",
    "    return x_raw_set.reshape(x, IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_and_x_set_from_dataframe(dataframe):\n",
    "    y_raw_set = dataframe[\"label\"].to_numpy(dtype=str)\n",
    "    x_raw_set = dataframe.iloc[:, 2:].to_numpy(dtype=np.uint8)\n",
    "\n",
    "    y_set = get_y_original_shape(y_raw_set)\n",
    "    x_set = get_x_original_shape(x_raw_set)\n",
    "\n",
    "    return y_set, x_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_x_y_from_csv_multi_process(path, engine, chunk_size):\n",
    "    chunks = pd.read_csv(path, chunksize=chunk_size, engine=engine)\n",
    "    cpu_count = mp.cpu_count()\n",
    "\n",
    "    with mp.Pool(cpu_count) as pool:\n",
    "        data_list = [data for data in pool.map(get_y_and_x_set_from_dataframe, chunks)]\n",
    "\n",
    "    data = list(zip(*data_list))\n",
    "    y_set = np.concatenate(data[0])\n",
    "    x_set = np.concatenate(data[1])\n",
    "\n",
    "    return y_set, x_set\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287911, 1)\n",
      "(287911, 41, 41)\n",
      "(123391, 1)\n",
      "(123391, 41, 41)\n"
     ]
    }
   ],
   "source": [
    "y_train, x_train = get_x_y_from_csv_multi_process(TRAIN_SET_PATH, PANDA_CSV_ENGINE, CHUNK_SIZE)\n",
    "y_test, x_test = get_x_y_from_csv_multi_process(TEST_SET_PATH, PANDA_CSV_ENGINE, CHUNK_SIZE)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère tous les labels possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "label_list = [char for char in ascii_lowercase + ascii_uppercase]\n",
    "print(label_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit l'encoder à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LabelBinarizer()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>LabelBinarizer()</pre></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On encode nos données au format OneShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(287911, 52)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded_train = encoder.transform(y_train)\n",
    "y_encoded_test = encoder.transform(y_test)\n",
    "y_encoded_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 1681)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               168200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 52)                5252      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,752\n",
      "Trainable params: 203,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(41,41)),\n",
    "    layers.Flatten(input_shape=(41, 41)),\n",
    "    layers.Dense(200, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(200, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(200, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(200, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(52, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"acc\", \"categorical_crossentropy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de tensorboard si installé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 02:05:29.124403: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 483978391 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8998/8998 [==============================] - 23s 2ms/step - loss: 1.7573 - acc: 0.5228 - categorical_crossentropy: 1.7573\n",
      "Epoch 2/20\n",
      "8998/8998 [==============================] - 22s 2ms/step - loss: 0.9881 - acc: 0.7054 - categorical_crossentropy: 0.9881\n",
      "Epoch 3/20\n",
      "8998/8998 [==============================] - 21s 2ms/step - loss: 0.8228 - acc: 0.7468 - categorical_crossentropy: 0.8228\n",
      "Epoch 4/20\n",
      "8998/8998 [==============================] - 22s 2ms/step - loss: 0.7400 - acc: 0.7687 - categorical_crossentropy: 0.7400\n",
      "Epoch 5/20\n",
      "8998/8998 [==============================] - 23s 3ms/step - loss: 0.6883 - acc: 0.7816 - categorical_crossentropy: 0.6883\n",
      "Epoch 6/20\n",
      "8998/8998 [==============================] - 23s 3ms/step - loss: 0.6520 - acc: 0.7907 - categorical_crossentropy: 0.6520\n",
      "Epoch 7/20\n",
      "8998/8998 [==============================] - 24s 3ms/step - loss: 0.6239 - acc: 0.7979 - categorical_crossentropy: 0.6239\n",
      "Epoch 8/20\n",
      "8998/8998 [==============================] - 23s 3ms/step - loss: 0.6022 - acc: 0.8037 - categorical_crossentropy: 0.6022\n",
      "Epoch 9/20\n",
      "8998/8998 [==============================] - 22s 2ms/step - loss: 0.5836 - acc: 0.8090 - categorical_crossentropy: 0.5836\n",
      "Epoch 10/20\n",
      "8998/8998 [==============================] - 23s 3ms/step - loss: 0.5669 - acc: 0.8139 - categorical_crossentropy: 0.5669\n",
      "Epoch 11/20\n",
      "8998/8998 [==============================] - 22s 2ms/step - loss: 0.5538 - acc: 0.8169 - categorical_crossentropy: 0.5538\n",
      "Epoch 12/20\n",
      "8998/8998 [==============================] - 25s 3ms/step - loss: 0.5426 - acc: 0.8195 - categorical_crossentropy: 0.5426\n",
      "Epoch 13/20\n",
      "8998/8998 [==============================] - 21s 2ms/step - loss: 0.5319 - acc: 0.8223 - categorical_crossentropy: 0.5319\n",
      "Epoch 14/20\n",
      "8998/8998 [==============================] - 21s 2ms/step - loss: 0.5230 - acc: 0.8248 - categorical_crossentropy: 0.5230\n",
      "Epoch 15/20\n",
      "8998/8998 [==============================] - 21s 2ms/step - loss: 0.5146 - acc: 0.8263 - categorical_crossentropy: 0.5146\n",
      "Epoch 16/20\n",
      "8998/8998 [==============================] - 24s 3ms/step - loss: 0.5068 - acc: 0.8295 - categorical_crossentropy: 0.5068\n",
      "Epoch 17/20\n",
      "8998/8998 [==============================] - 22s 2ms/step - loss: 0.5003 - acc: 0.8303 - categorical_crossentropy: 0.5003\n",
      "Epoch 18/20\n",
      "8998/8998 [==============================] - 21s 2ms/step - loss: 0.4938 - acc: 0.8313 - categorical_crossentropy: 0.4938\n",
      "Epoch 19/20\n",
      "8998/8998 [==============================] - 24s 3ms/step - loss: 0.4878 - acc: 0.8335 - categorical_crossentropy: 0.4878\n",
      "Epoch 20/20\n",
      "8998/8998 [==============================] - 21s 2ms/step - loss: 0.4820 - acc: 0.8355 - categorical_crossentropy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f8fb7a9d150>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_encoded_train, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du modèle sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3856/3856 - 8s - loss: 0.7403 - acc: 0.7694 - categorical_crossentropy: 0.7403 - 8s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.7402697801589966, 0.7694321274757385, 0.7402697801589966]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_encoded_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sauvegarde du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
