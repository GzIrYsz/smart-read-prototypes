{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848f69b6",
   "metadata": {},
   "source": [
    "# Construction des dictionnaires pour la Correction Lexicale\n",
    "\n",
    "Dans ce notebook sera présenté le pré-traitement du jeu de donnée [Lexique3](https://chrplr.github.io/openlexicon/datasets-info/) afin d'obtenir des données utilisable par notre algorithme de correction lexicale.\n",
    "\n",
    "Ce pré-traitement de donnée aura plusieurs objectifs :\n",
    "- Nettoyer le jeu de données de toutes ses impuretés (doublons, accents, etc...)\n",
    "- Augmenter la vitesse de notre algo de correction lexicale en divisant le dataset\n",
    "\n",
    "**Pour exécuter le notebook, mettre le dossier xlsx de Lexique3 dans le dossier dataset en le nommant liste_de_mots.xlsx**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c8242",
   "metadata": {},
   "source": [
    "## Importation des ressources nécessaires\n",
    "\n",
    "### Importation des dépandances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "39af46e6",
   "metadata": {},
   "source": [
    "### Importation du dataset en format excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(io=\"../dataset/liste_de_mots.xlsx\", dtype=str)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88d4c9",
   "metadata": {},
   "source": [
    "## Pré-traitement des données pour la création du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f91b0",
   "metadata": {},
   "source": [
    "### Organisation du dataset\n",
    "\n",
    "Récupération des colonnes utiles, dans notre cas nous avons juste besoin de la colonne **ortho** pour **orthographe** des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  pd.DataFrame(data[\"ortho\"], dtype=str)\n",
    "dataset.drop_duplicates(keep = 'first', inplace=True) # Supression des doublons\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d92957",
   "metadata": {},
   "source": [
    "### Nettoyage du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ff416",
   "metadata": {},
   "source": [
    "#### Suppression des accents et autres caractères français compliquant l'utilisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb811230",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avant conversion\")\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc091d4",
   "metadata": {},
   "source": [
    "Opération de conversion des str avec accents en str sans accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53765c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.applymap(unidecode)\n",
    "dataset.head(10)\n",
    "\n",
    "print(\"Après conversion\")\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb44ec",
   "metadata": {},
   "source": [
    "### Triage le dataset\n",
    "\n",
    "Le tri du dataset par nombre de lettre aura pour but de séparer le dataset en sous fichier pour ainsi augmenter la vitesse de calcule de \"la distance de Levensthein\" en sélectionnant ces fichers en fonctions du mot demandé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd82be",
   "metadata": {},
   "source": [
    "#### Analyse de la répartition des mots par nombre de caractères dans le dataset\n",
    "\n",
    "Pour cela, on crée une nouvelle colonne nb_caractères qui contiendra le nombre de caractères contenue dans chaque mots en fonction de la ligne de celui-ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nb_caracteres = dataset.applymap(len)\n",
    "dataset_nb_caracteres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35648e",
   "metadata": {},
   "source": [
    "Création du nouveau dataframe \"dataset_3\" contenant comme colonne:\n",
    "-mot\n",
    "-nombre de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = pd.DataFrame({\"mot\": dataset[\"ortho\"], \"nb_caracteres\": dataset_nb_caracteres[\"ortho\"]})\n",
    "dataset_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca9e19",
   "metadata": {},
   "source": [
    "Affichage de l'histogramme de la répartition du nombre de mots en fonction du nombre de caractère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2[\"nb_caracteres\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deabd3c",
   "metadata": {},
   "source": [
    "#### Regroupement des mots par nombre de caractère.\n",
    "\n",
    "On regroupe les mots par nombre de caractère afin d'obtenir une répartition plus uniformes des ensembles de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ed3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dataset_mots_par_nb_carac = {}\n",
    "for i in range(1, 26):\n",
    "    df = dataset_2 # Varaible intermédiaire pour simplifier l'écriture de la ligne suivante\n",
    "    dict_dataset_mots_par_nb_carac[i] = df[df[\"nb_caracteres\"] == i][\"mot\"] # On sélectionne uniquement la colonne des mots; plus besoin de la colonne du nombre de caractères\n",
    "\n",
    "dict_dataset_mots_par_nb_carac[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd53c966",
   "metadata": {},
   "source": [
    "#### Regroupement des catégories où il y a peu de mots ensemble\n",
    "\n",
    "Dans notre cas on va créer une nouvelle catégorie qui va reprendre tous les mots ayant les nombres de caractères ci-dessous:\n",
    "**(14, 4, 15, 3, 16, 17, 2, 18, 19, 1, 20, 21, 22, 23, 24, 25)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52267d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupe_autre = [14, 4, 15, 3, 16, 17, 2, 18, 19, 1, 20, 21, 22, 23, 24, 25]\n",
    "dataset_autre = pd.DataFrame(dtype=str)\n",
    "\n",
    "for i in groupe_autre:\n",
    "    dataset_autre = pd.concat((dataset_autre, dict_dataset_mots_par_nb_carac[i]))\n",
    "dataset_autre.columns = [\"mot\"]\n",
    "dataset_autre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02531747",
   "metadata": {},
   "source": [
    "##### Création du dataset final dans un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4797eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_final_dataset = {}\n",
    "dict_final_dataset[\"autre\"] = dataset_autre\n",
    "\n",
    "for i in range(1, 26):\n",
    "    if i not in groupe_autre:\n",
    "        dict_final_dataset[i] = dict_dataset_mots_par_nb_carac[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967987a8",
   "metadata": {},
   "source": [
    "##### Affichage de la répartition des ensembles de  mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_final_dataset_repartion_mots = {}\n",
    "\n",
    "for key, value in dict_final_dataset.items():\n",
    "    dict_final_dataset_repartion_mots[key] = len(value.index)\n",
    "\n",
    "print(dict_final_dataset_repartion_mots)\n",
    "plt.bar(range(len(dict_final_dataset_repartion_mots)), list(dict_final_dataset_repartion_mots.values()), align='center')\n",
    "plt.xticks(range(len(dict_final_dataset_repartion_mots)), list(dict_final_dataset_repartion_mots.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b28b06",
   "metadata": {},
   "source": [
    "##### Sauvegarde du dataset sur le PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"../dataset/\")\n",
    "for key in dict_final_dataset.keys():\n",
    "    dict_final_dataset[key].to_csv(SAVE_PATH / f\"mots_{key}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "9244ba990cb9167d000ed53547d873aef74d718570944566aedb44fcca32ff7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
